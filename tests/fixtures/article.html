<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>How to Extract Structured Content for LLMs | Tech Blog</title>
  <meta name="description" content="A comprehensive guide to extracting clean, structured content from any website so LLMs can parse and understand it.">
  <meta name="author" content="Jane Smith">
  <meta property="og:title" content="How to Extract Structured Content for LLMs">
  <meta property="og:description" content="A comprehensive guide to extracting clean, structured content from any website so LLMs can parse and understand it.">
  <meta property="og:site_name" content="Tech Blog">
  <meta property="og:type" content="article">
  <meta property="og:image" content="https://example.com/img/diagram.png">
  <meta property="og:image:alt" content="Architecture diagram">
  <meta property="article:published_time" content="2024-01-15T10:00:00Z">
  <meta property="article:modified_time" content="2024-01-16T08:00:00Z">
  <meta property="article:author" content="Jane Smith">
  <meta property="article:tag" content="python">
  <meta property="article:tag" content="web-scraping">
  <link rel="canonical" href="https://example.com/blog/how-to-extract-structured-content-for-llms">
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "headline": "How to Extract Structured Content for LLMs",
    "author": {"@type": "Person", "name": "Jane Smith"},
    "datePublished": "2024-01-15T10:00:00Z",
    "dateModified": "2024-01-16T08:00:00Z",
    "description": "A comprehensive guide to extracting clean, structured content from any website so LLMs can parse and understand it.",
    "keywords": "python, web-scraping, llm, content-extraction"
  }
  </script>
</head>
<body>
  <nav>
    <a href="/">Home</a>
    <a href="/blog">Blog</a>
    <a href="/about">About</a>
  </nav>
  <article>
    <h1>How to Extract Structured Content for LLMs</h1>
    <p class="byline">By Jane Smith | January 15, 2024</p>

    <p>Feeding an LLM raw HTML is wasteful and noisy. The goal of LLMParser is to
    extract clean, structured content from any website so language models can parse
    and understand it efficiently — without site-specific selectors or manual rules.</p>

    <h2>Getting Started</h2>

    <p>The key insight is that websites, despite their visual variety, all have similar
    structural patterns: a title, some metadata, and a body of content. LLMParser
    identifies and extracts these patterns deterministically.</p>

    <pre><code class="language-python">from llmparser import fetch

article = fetch("https://example.com/blog/post")
print(article.title)
print(article.content_markdown)   # clean Markdown ready for LLM context
print(article.content_blocks)     # structured typed blocks
</code></pre>

    <h2>Handling Different Page Types</h2>

    <p>Different sites render content differently. The adaptive engine classifies each
    page as Static HTML, JS SPA, Cookie-walled, or Paywalled, then selects the optimal
    fetch strategy automatically — no configuration required.</p>

    <ul>
      <li>Static HTML: fast urllib fetch, no browser overhead</li>
      <li>JS SPA: Playwright headless Chromium with 4-phase rendering wait</li>
      <li>AMP: fetch the lightweight AMP URL instead of the main page</li>
      <li>RSS/Atom: parse the feed and extract each linked article</li>
    </ul>

    <h2>Structured Output for LLMs</h2>

    <p>Most modern websites include rich metadata in JSON-LD, Open Graph, or Twitter Card
    format. LLMParser combines these with extracted article content to produce a clean
    Pydantic schema — title, author, date, tags, Markdown body, and typed content blocks.</p>

    <blockquote>
      <p>The best parsers are the ones that work on any site without modification.</p>
    </blockquote>

    <h2>Performance Considerations</h2>

    <p>When parsing at scale, you need to be polite to the servers you are crawling.
    LLMParser uses Scrapy's AutoThrottle middleware to automatically adjust crawl speed
    based on server latency, respects robots.txt, and honours Retry-After headers on
    rate-limited responses.</p>

    <figure>
      <img src="https://example.com/img/diagram.png" alt="Architecture diagram">
      <figcaption>Figure 1: LLMParser adaptive engine architecture</figcaption>
    </figure>

    <p>With these techniques, LLMParser reliably extracts content from virtually any
    website on the internet, regardless of its technical stack or visual design,
    delivering clean structured data ready for LLM consumption.</p>
  </article>
  <footer>
    <p>&copy; 2024 Tech Blog</p>
  </footer>
</body>
</html>
